{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_strings = \"I am learning Natural Language Processing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(my_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'learning', 'Natural', 'Language', 'Processing', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"I am learning Natural Learning Processing. I am learning how to tokenize!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_sent = nltk.sent_tokenize(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am learning Natural Learning Processing.',\n",
       " 'I am learning how to tokenize!']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'learning', 'Natural', 'Learning', 'Processing', '.']\n",
      "['I', 'am', 'learning', 'how', 'to', 'tokenize', '!']\n"
     ]
    }
   ],
   "source": [
    "for item in tokens_sent:\n",
    "    print(nltk.word_tokenize(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------\n",
    "# NORMALIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = nltk.corpus.gutenberg.words(\"melville-moby_dick.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_22 = md[:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moby\n",
      "Dick\n",
      "by\n",
      "Herman\n",
      "Melville\n",
      "ETYMOLOGY\n",
      "Supplied\n",
      "by\n",
      "a\n",
      "Late\n",
      "Consumptive\n",
      "Usher\n",
      "to\n",
      "a\n",
      "Grammar\n",
      "School\n"
     ]
    }
   ],
   "source": [
    "# Get only proper words, not dates or punctuations etc.\n",
    "for word in md_22:\n",
    "    if word.isalpha():\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "moby\n",
      "dick\n",
      "by\n",
      "herman\n",
      "melville\n",
      "1851\n",
      "]\n",
      "etymology\n",
      ".\n",
      "(\n",
      "supplied\n",
      "by\n",
      "a\n",
      "late\n",
      "consumptive\n",
      "usher\n",
      "to\n",
      "a\n",
      "grammar\n",
      "school\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Change all words to same case\n",
    "for word in md_22:\n",
    "    print(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = [word.lower() for word in md_22 if word.isalpha()]\n",
    "# Normalizing or Text-Preprocessing refers to the following:\n",
    "# 1. converting all letters to lower or upper case.\n",
    "# 2. converting numbers into words or removing numbers.\n",
    "# 3. removing punctuations, accent marks and other diacritics.\n",
    "# 4. removing white spaces.\n",
    "# 5. expanding abbreviations.\n",
    "# 6. removing stop words, sparse terms, and particular words.\n",
    "# 7. text canonicalization.\n",
    "\n",
    "# Great link: https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moby',\n",
       " 'dick',\n",
       " 'by',\n",
       " 'herman',\n",
       " 'melville',\n",
       " 'etymology',\n",
       " 'supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'late',\n",
       " 'consumptive',\n",
       " 'usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'grammar',\n",
       " 'school']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat', 'lie', 'lie', 'run', 'run', 'citi', 'citi', 'woman', 'women', 'organ', 'organ', 'organ']\n"
     ]
    }
   ],
   "source": [
    "# Using stemmers - Porter\n",
    "porter = nltk.PorterStemmer()\n",
    "my_list = [\"cat\", \"cats\", \"lie\", \"lying\", \"run\", \"running\", \"city\", \"cities\", \"woman\", \"women\", \"organize\", \"organization\", \"organizations\"]\n",
    "print([porter.stem(word) for word in my_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat', 'lie', 'lying', 'run', 'run', 'city', 'city', 'wom', 'wom', 'org', 'org', 'org']\n"
     ]
    }
   ],
   "source": [
    "# Using stemmers - Lancester\n",
    "lanc = nltk.LancasterStemmer()\n",
    "print([lanc.stem(word) for word in my_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat', 'lie', 'lying', 'run', 'running', 'city', 'city', 'woman', 'woman', 'organize', 'organization', 'organization']\n"
     ]
    }
   ],
   "source": [
    "# Using Lemmitization\n",
    "wn_lem = nltk.WordNetLemmatizer()\n",
    "print([wn_lem.lemmatize(word) for word in my_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
